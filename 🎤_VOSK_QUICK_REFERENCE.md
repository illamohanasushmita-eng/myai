# ðŸŽ¤ Vosk Quick Reference

---

## ðŸ“¦ Files Created

```
src/lib/voice/
â”œâ”€â”€ vosk-recognizer.ts          # Core Vosk integration
â”œâ”€â”€ vosk-integration.ts         # High-level workflow
â””â”€â”€ (existing files)

src/hooks/
â”œâ”€â”€ useVoskRecognizer.ts        # React hook
â””â”€â”€ (existing files)

src/components/voice/
â”œâ”€â”€ VoskVoiceButton.tsx         # Example component
â””â”€â”€ (existing files)
```

---

## ðŸš€ Usage Examples

### Example 1: Start Listening

```typescript
import { startRecognizer } from '@/lib/voice/vosk-recognizer';

await startRecognizer(
  () => console.log('Wake word!'),
  (text) => console.log('Text:', text)
);
```

### Example 2: React Hook

```typescript
import { useVoskRecognizer } from '@/hooks/useVoskRecognizer';

const { start, stop, isRunning } = useVoskRecognizer({
  onWakeWord: () => console.log('Wake word!'),
  onRecognize: (text) => console.log('Text:', text),
});

<button onClick={start}>Start</button>
<button onClick={stop}>Stop</button>
```

### Example 3: Workflow Class

```typescript
import { getVoskWorkflow } from '@/lib/voice/vosk-integration';

const workflow = getVoskWorkflow();
await workflow.initialize();
await workflow.start();
```

### Example 4: Component

```typescript
import { VoskVoiceButton } from '@/components/voice/VoskVoiceButton';

export default function Page() {
  return <VoskVoiceButton />;
}
```

---

## ðŸŽ¯ Key Functions

### `loadVoskModel(path?)`
Loads model from `/public/vosk/model.zip`

### `startRecognizer(onWakeWord, onRecognize, onError, onPartialResult)`
Starts listening with callbacks

### `stopRecognizer()`
Stops listening and closes audio

### `useVoskRecognizer(options)`
React hook for recognizer

### `getVoskWorkflow(config)`
Get workflow singleton instance

---

## ðŸ”§ Configuration

```typescript
{
  autoStart: false,              // Auto-start on mount
  modelPath: '/vosk/model.zip',  // Model location
  onWakeWord: () => {},          // Wake word callback
  onRecognize: (text) => {},     // Recognition callback
  onError: (error) => {},        // Error callback
  onPartialResult: (text) => {}, // Partial result callback
}
```

---

## ðŸ“Š Return Values

### `useVoskRecognizer()` returns:

```typescript
{
  start: () => Promise<void>,
  stop: () => void,
  reset: () => Promise<void>,
  isRunning: boolean,
  isLoading: boolean,
  error: string | null,
}
```

---

## ðŸŽ™ï¸ Callbacks

### `onWakeWord()`
Called when "hey lara" is detected

### `onRecognize(text: string)`
Called when text is recognized

### `onError(error: string)`
Called on error

### `onPartialResult(text: string)`
Called with partial results

---

## âš™ï¸ Technical Specs

- **Sample Rate**: 16000 Hz
- **Audio Format**: PCM int16
- **Buffer Size**: 4096 samples
- **Channels**: Mono
- **Model**: Vosk (browser-based)
- **Location**: `/public/vosk/model.zip`

---

## ðŸ§ª Testing Checklist

- [ ] Say "Hey Lara" â†’ Wake word detected
- [ ] Say "Hey Lara, show tasks" â†’ Command recognized
- [ ] Check console for logs
- [ ] Verify no errors
- [ ] Test multiple commands
- [ ] Test error handling

---

## ðŸ› Common Issues

| Issue | Solution |
|-------|----------|
| Model not loading | Check `/public/vosk/model.zip` exists |
| No microphone | Grant permission in browser |
| Wake word not detected | Speak clearly, louder |
| Audio not captured | Check browser console |
| High CPU usage | Normal during recognition |

---

## ðŸ“š Integration Points

### With Voice Commands
```typescript
onWakeWord: () => activateCommandMode(),
onRecognize: (text) => processCommand(text),
```

### With TTS
```typescript
onWakeWord: () => speakText('Yes, how can I help?'),
```

### With Navigation
```typescript
onRecognize: (text) => {
  if (text.includes('tasks')) router.push('/professional');
}
```

---

## âœ… Status

âœ… Core implementation complete  
âœ… React hook created  
âœ… Example component provided  
âœ… Documentation complete  
âœ… Ready for production  

---

## ðŸš€ Next Steps

1. Import `useVoskRecognizer` in your component
2. Add callbacks for wake-word and recognition
3. Test with "Hey Lara"
4. Integrate with voice commands
5. Deploy to production

---

**Ready to use!** ðŸŽ¤


