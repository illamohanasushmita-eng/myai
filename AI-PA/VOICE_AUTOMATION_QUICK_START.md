# ğŸš€ Voice Automation Quick Start

**Time**: 5 minutes  
**Status**: âœ… Ready to Use

---

## ğŸ“¦ What's Included

âœ… Complete voice automation workflow  
âœ… Wake word detection ("Hey Lara")  
âœ… Intent classification (Gemini AI)  
âœ… Spotify music automation  
âœ… Task management automation  
âœ… Reminder automation  
âœ… Navigation automation  
âœ… Voice response (TTS)  
âœ… React hook for easy integration

---

## ğŸ¯ Quick Integration

### Step 1: Import the Hook

```typescript
import { useVoiceAutomation } from "@/hooks/useVoiceAutomation";
```

### Step 2: Use in Component

```typescript
export function DashboardPage() {
  const {
    isListening,
    isProcessing,
    transcript,
    lastResult,
    startListening,
    stopListening,
  } = useVoiceAutomation({
    userId: 'user-123',
    onSuccess: (result) => {
      console.log('âœ… Command executed:', result.response);
    },
    onError: (error) => {
      console.error('âŒ Error:', error.message);
    },
  });

  return (
    <div>
      <button onClick={startListening}>
        {isListening ? 'Listening...' : 'Start Voice Command'}
      </button>
      <button onClick={stopListening}>Stop</button>
      {transcript && <p>You said: {transcript}</p>}
      {lastResult && <p>Response: {lastResult.response}</p>}
    </div>
  );
}
```

---

## ğŸ¤ Voice Commands

### Music Commands

```
"Hey Lara, play a song"
"Hey Lara, play romantic Telugu songs"
"Hey Lara, play my favorite hero songs"
```

### Task Commands

```
"Hey Lara, add a task"
"Hey Lara, add buy groceries to my task list"
"Hey Lara, show my tasks"
```

### Reminder Commands

```
"Hey Lara, add reminder at 5 PM"
"Hey Lara, remind me to call mom"
"Hey Lara, show my reminders"
```

### Navigation Commands

```
"Hey Lara, go to tasks page"
"Hey Lara, open reminders section"
"Hey Lara, go to health"
"Hey Lara, show my work"
```

---

## ğŸ“ File Structure

```
src/
â”œâ”€â”€ lib/voice/
â”‚   â”œâ”€â”€ voice-automation.ts          # Main workflow
â”‚   â”œâ”€â”€ spotify-automation.ts        # Music automation
â”‚   â”œâ”€â”€ task-automation.ts           # Task automation
â”‚   â”œâ”€â”€ reminder-automation.ts       # Reminder automation
â”‚   â””â”€â”€ navigation-automation.ts     # Navigation automation
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useVoiceAutomation.ts        # React hook
â””â”€â”€ app/api/ai/voice-automation/
    â””â”€â”€ classify/route.ts            # Intent classification API
```

---

## ğŸ”„ Workflow

```
1. User says "Hey Lara"
   â†“
2. System detects wake word
   â†“
3. Speaks "Yes, how can I help?"
   â†“
4. User says command
   â†“
5. System classifies intent (Gemini AI)
   â†“
6. System executes action
   â†“
7. System speaks response
   â†“
âœ… Done
```

---

## ğŸ¯ Intent Classification

The system automatically classifies commands into:

- `play_music` - Music playback
- `add_task` - Create task
- `show_tasks` - View tasks
- `add_reminder` - Create reminder
- `show_reminders` - View reminders
- `navigate` - Go to section
- `general_query` - General questions

---

## ğŸ”§ Configuration

### Enable/Disable Voice Automation

```typescript
const { ... } = useVoiceAutomation({
  userId: 'user-123',
  enabled: true,  // Enable/disable
  language: 'en-US',  // Language
});
```

### Custom Language

```typescript
const { ... } = useVoiceAutomation({
  userId: 'user-123',
  language: 'es-ES',  // Spanish
});
```

---

## ğŸš€ Advanced Usage

### Direct Function Calls

```typescript
import { voiceAutomation } from "@/lib/voice/voice-automation";

const result = await voiceAutomation("Hey Lara, play a song", userId, context);
```

### Spotify Automation

```typescript
import { automateSpotifyPlayback } from "@/lib/voice/spotify-automation";

await automateSpotifyPlayback("romantic songs", userId);
```

### Task Automation

```typescript
import { addTaskVoice } from "@/lib/voice/task-automation";

await addTaskVoice("Buy groceries", userId);
```

### Reminder Automation

```typescript
import { addReminderVoice } from "@/lib/voice/reminder-automation";

await addReminderVoice("Call mom", userId, "17:00");
```

### Navigation Automation

```typescript
import { navigateVoice } from "@/lib/voice/navigation-automation";

await navigateVoice("tasks", router);
```

---

## ğŸ§ª Testing

### Test Wake Word Detection

```typescript
import { detectWakeWord } from "@/lib/voice/voice-automation";

const detected = detectWakeWord("Hey Lara, play a song");
console.log(detected); // true
```

### Test Intent Classification

```typescript
import { classifyIntent } from "@/lib/voice/voice-automation";

const intent = await classifyIntent("play romantic songs");
console.log(intent); // { intent: 'play_music', musicQuery: 'romantic songs', ... }
```

### Test Voice Response

```typescript
import { speakResponse } from "@/lib/voice/voice-automation";

await speakResponse("Playing your song now");
```

---

## ğŸ› Troubleshooting

### Issue: Voice not recognized

- Check microphone permissions
- Verify browser supports Web Speech API
- Check console for errors

### Issue: Commands not executing

- Verify userId is correct
- Check API endpoints are working
- Review console for error messages

### Issue: Spotify not playing

- Verify Spotify credentials in .env
- Check user has Spotify account
- Review API response in network tab

---

## ğŸ“Š Status

âœ… Implementation: COMPLETE  
âœ… Testing: READY  
âœ… Documentation: COMPLETE  
âœ… Deployment: READY

---

## ğŸ‰ You're Ready!

Your voice automation workflow is ready to use. Start integrating it into your components!

**Next Steps**:

1. Import `useVoiceAutomation` hook
2. Add to your component
3. Test voice commands
4. Deploy to production

---

**Status**: âœ… READY FOR PRODUCTION
